{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dash_bootstrap_components\n",
      "  Downloading https://files.pythonhosted.org/packages/22/3c/57326a03c25dd59e4b1aa4c3a237b2fdc7dd2152e2c0e35939757e7eb34b/dash-bootstrap-components-0.9.2.tar.gz (107kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "Requirement already satisfied: dash>=1.9.0 in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from dash_bootstrap_components) (1.11.0)\n",
      "Requirement already satisfied: future in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from dash>=1.9.0->dash_bootstrap_components) (0.17.1)\n",
      "Requirement already satisfied: dash-table==4.6.2 in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from dash>=1.9.0->dash_bootstrap_components) (4.6.2)\n",
      "Requirement already satisfied: dash-html-components==1.0.3 in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from dash>=1.9.0->dash_bootstrap_components) (1.0.3)\n",
      "Requirement already satisfied: Flask>=1.0.2 in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from dash>=1.9.0->dash_bootstrap_components) (1.0.2)\n",
      "Requirement already satisfied: dash-core-components==1.9.1 in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from dash>=1.9.0->dash_bootstrap_components) (1.9.1)\n",
      "Requirement already satisfied: flask-compress in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from dash>=1.9.0->dash_bootstrap_components) (1.4.0)\n",
      "Requirement already satisfied: plotly in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from dash>=1.9.0->dash_bootstrap_components) (3.8.1)\n",
      "Requirement already satisfied: dash-renderer==1.4.0 in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from dash>=1.9.0->dash_bootstrap_components) (1.4.0)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from Flask>=1.0.2->dash>=1.9.0->dash_bootstrap_components) (7.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from Flask>=1.0.2->dash>=1.9.0->dash_bootstrap_components) (1.1.0)\n",
      "Requirement already satisfied: Jinja2>=2.10 in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from Flask>=1.0.2->dash>=1.9.0->dash_bootstrap_components) (2.10)\n",
      "Requirement already satisfied: Werkzeug>=0.14 in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from Flask>=1.0.2->dash>=1.9.0->dash_bootstrap_components) (0.14.1)\n",
      "Requirement already satisfied: decorator>=4.0.6 in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from plotly->dash>=1.9.0->dash_bootstrap_components) (4.3.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from plotly->dash>=1.9.0->dash_bootstrap_components) (2018.7)\n",
      "Requirement already satisfied: retrying>=1.3.3 in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from plotly->dash>=1.9.0->dash_bootstrap_components) (1.3.3)\n",
      "Requirement already satisfied: nbformat>=4.2 in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from plotly->dash>=1.9.0->dash_bootstrap_components) (4.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from plotly->dash>=1.9.0->dash_bootstrap_components) (2.21.0)\n",
      "Requirement already satisfied: six in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from plotly->dash>=1.9.0->dash_bootstrap_components) (1.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from Jinja2>=2.10->Flask>=1.0.2->dash>=1.9.0->dash_bootstrap_components) (1.1.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from nbformat>=4.2->plotly->dash>=1.9.0->dash_bootstrap_components) (4.4.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from nbformat>=4.2->plotly->dash>=1.9.0->dash_bootstrap_components) (2.6.0)\n",
      "Requirement already satisfied: traitlets>=4.1 in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from nbformat>=4.2->plotly->dash>=1.9.0->dash_bootstrap_components) (4.3.2)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from nbformat>=4.2->plotly->dash>=1.9.0->dash_bootstrap_components) (0.2.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from requests->plotly->dash>=1.9.0->dash_bootstrap_components) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from requests->plotly->dash>=1.9.0->dash_bootstrap_components) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from requests->plotly->dash>=1.9.0->dash_bootstrap_components) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (from requests->plotly->dash>=1.9.0->dash_bootstrap_components) (3.0.4)\n",
      "Building wheels for collected packages: dash-bootstrap-components\n",
      "  Running setup.py bdist_wheel for dash-bootstrap-components: started\n",
      "  Running setup.py bdist_wheel for dash-bootstrap-components: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Omkar Mehta\\AppData\\Local\\pip\\Cache\\wheels\\d4\\c6\\89\\8d02b445bb1976020fe292b19fb02b6c0ef6388cd4a2f859eb\n",
      "Successfully built dash-bootstrap-components\n",
      "Installing collected packages: dash-bootstrap-components\n",
      "Successfully installed dash-bootstrap-components-0.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install dash_bootstrap_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dash_table in c:\\users\\omkar mehta\\anaconda3\\lib\\site-packages (4.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install dash_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Omkar\n",
      "[nltk_data]     Mehta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Omkar\n",
      "[nltk_data]     Mehta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Omkar\n",
      "[nltk_data]     Mehta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#data_preprocessing\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import randint as sp_randint\n",
    "from time import time\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "#from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from bs4 import BeautifulSoup \n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "\n",
    "replace_space = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "bad_symbols = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "####Display some stats\n",
    "def preprocess(text):\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = replace_space.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = bad_symbols.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text \n",
    "\n",
    "\n",
    "   \n",
    "def train_cleaning(dataset):\n",
    "    \n",
    "    ##Fill missing values of Host with that link in the same row\n",
    "    for i in list(dataset[dataset['Host'].isnull() == True]['Host'].index):\n",
    "        dataset.at[i,'Host'] = dataset.loc[i]['Link']\n",
    "    \n",
    "    ##Filling missing value of TRANS_CONV_TEXT with that of title\n",
    "    for i in list(dataset[dataset['TRANS_CONV_TEXT'].isnull() == True].index):\n",
    "        dataset.at[i, 'TRANS_CONV_TEXT'] = dataset.loc[i]['Title']\n",
    "    ##Converting 'Date(ET)' object to datetime\n",
    "    dataset['Date(ET)'] = pd.to_datetime(dataset['Date(ET)'], infer_datetime_format=True)    \n",
    "\n",
    "    ##Converting Datetime to timestamp\n",
    "    dataset['Date(ET)'] = dataset[['Date(ET)']].apply(lambda x: x[0].timestamp(), axis = 1).astype(int)\n",
    "\n",
    "    ##Dropping time(ET) and time(GMT)\n",
    "    dataset.drop(['Date(ET)', 'Time(ET)', 'time(GMT)'], axis = 1, inplace = True)\n",
    "\n",
    "    ##Fill missing values of Title with that of TRANS_CONV_TEXT in the same row\n",
    "    for i in list(dataset[dataset['Title'].isnull() == True]['Title'].index):\n",
    "        dataset.at[i,'Title'] = dataset.loc[i]['TRANS_CONV_TEXT']\n",
    "\n",
    "    #feature_selection\n",
    "    y = dataset['Patient_Tag'].tolist()\n",
    "\n",
    "    dataset['Story'] = 'a'\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        dataset.at[i, 'Story'] = dataset['Source'][i] + ' ' + dataset['Host'][i] + ' ' + str(dataset['Link'][i]) + ' ' + dataset['Title'][i] + ' ' + dataset['TRANS_CONV_TEXT'][i]\n",
    "\n",
    "    dataset.drop(['Source', 'Host', 'Link', 'Title', 'TRANS_CONV_TEXT'], axis = 1, inplace = True)\n",
    "    dataset['Story'] = dataset['Story'].apply(preprocess)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def test_cleaning(test):\n",
    "    \n",
    "    \n",
    "    ##Fill missing values of Host with that link in the same row\n",
    "    for i in list(test[test['Host'].isnull() == True]['Host'].index):\n",
    "        test.at[i,'Host'] = test.loc[i]['Link']\n",
    "    \n",
    "    #Filling missing value of TRANS_CONV_TEXT with that of title\n",
    "    for i in list(test[test['TRANS_CONV_TEXT'].isnull() == True].index):\n",
    "        test.at[i, 'TRANS_CONV_TEXT'] = test.loc[i]['Title']\n",
    "\n",
    "    test.at[441,'Date(ET)'] = test.loc[441, 'Time(ET)']\n",
    "\n",
    "    #Converting 'Date(ET)' object to datetime\n",
    "    test['Date(ET)'] = pd.to_datetime(test['Date(ET)'], infer_datetime_format=True)    \n",
    "\n",
    "    #Converting Datetime to timestamp\n",
    "    test['Date(ET)'] = test[['Date(ET)']].apply(lambda x: x[0].timestamp(), axis = 1).astype(int)\n",
    "\n",
    "    #Dropping time(ET) and time(GMT)\n",
    "    test.drop(['Date(ET)','Time(ET)', 'time(GMT)'], axis = 1, inplace = True)\n",
    "\n",
    "    #Fill missing values of Title with that of TRANS_CONV_TEXT in the same row\n",
    "    for i in list(test[test['Title'].isnull() == True]['Title'].index):\n",
    "        test.at[i,'Title'] = test.loc[i]['TRANS_CONV_TEXT']\n",
    "\n",
    "    index = test['Index']\n",
    "    index = list(index)\n",
    "\n",
    "    test.drop(['Index'], axis = 1, inplace = True)\n",
    "    \n",
    "    test['Story'] = 'a'\n",
    "\n",
    "\n",
    "    for i in range(len(test)):\n",
    "        test.at[i, 'Story'] = test['Source'][i] + ' ' + test['Host'][i] + ' ' + str(test['Link'][i]) + ' ' + test['Title'][i] + ' ' + test['TRANS_CONV_TEXT'][i]\n",
    "\n",
    "    test.drop(['Source', 'Host', 'Link', 'Title', 'TRANS_CONV_TEXT', 'Unnamed: 9'], axis = 1, inplace = True)\n",
    "    \n",
    "    test['Story'] = test['Story'].apply(preprocess)\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [15/Apr/2020 18:20:11] \"\u001b[37mGET /page-2 HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Apr/2020 18:20:12] \"\u001b[37mGET /_dash-layout HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Apr/2020 18:20:12] \"\u001b[37mGET /_dash-dependencies HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Apr/2020 18:20:12] \"\u001b[37mGET /_favicon.ico?v=1.11.0 HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Apr/2020 18:20:12] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Apr/2020 18:20:12] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.graph_objs as go\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_table\n",
    "\n",
    "import base64\n",
    "import xlrd\n",
    "import io\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "print(dcc.__version__) # 0.6.0 or above is required\n",
    "\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "\n",
    "app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "\n",
    "\n",
    "# Since we're adding callbacks to elements that don't exist in the app.layout,\n",
    "# Dash will raise an exception to warn us that we might be\n",
    "# doing something wrong.\n",
    "# In this case, we're adding the elements through a callback, so we can ignore\n",
    "# the exception.\n",
    "app.config.suppress_callback_exceptions = True\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Location(id='url', refresh=False),\n",
    "    html.Div(id='page-content')\n",
    "])\n",
    "\n",
    "# Update the index\n",
    "@app.callback(dash.dependencies.Output('page-content', 'children'),\n",
    "              [dash.dependencies.Input('url', 'pathname')])\n",
    "def display_page(pathname):\n",
    "    if pathname == '/page-1':\n",
    "        return page_1_layout\n",
    "    elif pathname == '/page-2':\n",
    "        return page_2_layout\n",
    "    elif pathname == '/page-3':\n",
    "        return page_3_layout\n",
    "    elif pathname == '/page-4':\n",
    "        return page_4_layout\n",
    "    elif pathname == '/page-5':\n",
    "        return page_5_layout\n",
    "    elif pathname == '/page-6':\n",
    "        return page_6_layout\n",
    "    else:\n",
    "        return index_page\n",
    "    # You could also return a 404 \"URL not found\" page here\n",
    "    \n",
    "\n",
    "path = 'F:/Udemy/Plotly-Dashboards-with-Dash/0-00-DashTutorial/2-01-ProjectZSAssociate/'\n",
    "train_dataset = pd.read_excel(path+'train.xlsx')\n",
    "test_dataset = pd.read_csv(path+'test.csv')\n",
    "train = train_cleaning(train_dataset)\n",
    "test = test_cleaning(test_dataset)\n",
    "\n",
    "test_train_ratio = \"Size of test data as compared to train data is {:0.2f}%\".format(len(test)/len(train)*100)\n",
    "\n",
    "#Returning average word length of phrases for each dataset\n",
    "train_word_len = 'Average word length of phrases in train is {0:.0f}.'.format(\n",
    "    np.mean(train['Story'].apply(lambda x: len(x.split()))))\n",
    "test_word_len = 'Average word length of phrases in test is {0:.0f}.'.format(\n",
    "    np.mean(test['Story'].apply(lambda x: len(x.split()))))\n",
    "    \n",
    "patient_tags_count = train['Patient_Tag'].value_counts()\n",
    "index_page = html.Div([\n",
    "    html.H1('Social Listening'),\n",
    "    dcc.Link('Go to Page 1', href='/page-1'),\n",
    "    html.Br(),\n",
    "    dcc.Link('Go to Page 2', href='/page-2'),\n",
    "    html.Br(),\n",
    "    dcc.Link('Go to Page 3', href='/page-3'),\n",
    "    html.Br(),\n",
    "    dcc.Link('Go to Page 4', href='/page-4'),\n",
    "    html.Br(),\n",
    "    dcc.Link('Go to Page 5', href='/page-5'),\n",
    "    html.Br(),\n",
    "    dcc.Link('Go to Page 6', href='/page-6'),\n",
    "])\n",
    "\n",
    "######Page 1- Upload Button #####\n",
    "page_1_layout = html.Div([\n",
    "    html.H1('Page 1: Datasets'),\n",
    "    html.H4('Peeking at Training Data'),\n",
    "    html.Div(id = 'train-head', children = [html.Div([\n",
    "        dash_table.DataTable(\n",
    "            style_table={'overflowX': 'scroll'},\n",
    "            style_cell={\n",
    "        'overflow': 'hidden',\n",
    "        'textOverflow': 'ellipsis',\n",
    "        'maxWidth': 0,\n",
    "    },\n",
    "            data=train_dataset.loc[:5].to_dict('records'),\n",
    "            columns=[{'name': i, 'id': i} for i in train_dataset.columns]\n",
    "        ),\n",
    "\n",
    "        html.Hr(),  # horizontal line\n",
    "\n",
    "    ])\n",
    "]),\n",
    "    html.H4('Peeking at Test Data'),\n",
    "    html.Div(id = 'test-head', children = html.Div([\n",
    "        dash_table.DataTable(\n",
    "            style_table={'overflowX': 'scroll'},\n",
    "            style_cell={\n",
    "        'overflow': 'hidden',\n",
    "        'textOverflow': 'ellipsis',\n",
    "        'maxWidth': 0,\n",
    "    },\n",
    "            data= test_dataset.loc[:5].to_dict('records'),\n",
    "            columns=[{'name': i, 'id': i} for i in test_dataset.columns]\n",
    "        ),\n",
    "\n",
    "        html.Hr(),  # horizontal line\n",
    "\n",
    "    ])\n",
    "),\n",
    "    \n",
    "    html.H4('Dataset information'),\n",
    "    html.Div(id = 'overview', \n",
    "             children = [html.Div([\n",
    "        html.H5('Overview'),\n",
    "        html.Div([dcc.Markdown(test_train_ratio)]),\n",
    "        html.Hr(),\n",
    "        html.Div([dcc.Markdown(train_word_len)]),\n",
    "        html.Hr(),\n",
    "        html.Div([dcc.Markdown(test_word_len)]),\n",
    "        html.Hr(),\n",
    "    ])\n",
    "                        ]),\n",
    "    \n",
    "    html.Br(),\n",
    "    dcc.Link('Go to Page 2', href='/page-2'),\n",
    "    html.Br(),\n",
    "    dcc.Link('Go back to home', href='/'),\n",
    "])\n",
    "\n",
    "page_2_layout = html.Div([\n",
    "    html.H1('Page 2'),\n",
    "    dcc.Graph(\n",
    "        id='count-plot',\n",
    "        figure= {\n",
    "        'data' : [\n",
    "    go.Bar(\n",
    "        x = [0,1],\n",
    "        y= patient_tags_count,    \n",
    "    ),\n",
    "    ],\n",
    "        'layout' : go.Layout(\n",
    "            title = 'Count-Plot of Patients',\n",
    "            xaxis = dict(title = 'Labels', tickmode = 'array', tickvals = [0,1]),\n",
    "            yaxis = dict(title='Counts')),\n",
    "            \n",
    "        \n",
    "    }\n",
    "    ),\n",
    "    dcc.Link('Go to Page 1', href='/page-1'),\n",
    "    html.Br(),\n",
    "    dcc.Link('Go back to home', href='/')\n",
    "])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
